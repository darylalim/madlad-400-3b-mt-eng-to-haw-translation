{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6830b4d-cd2e-4547-b2ba-7c0192ee941a",
   "metadata": {
    "id": "e6830b4d-cd2e-4547-b2ba-7c0192ee941a"
   },
   "source": [
    "# MADLAD-400 Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a6996-891a-45e0-bedd-10bcb36a5a2b",
   "metadata": {
    "id": "c07a6996-891a-45e0-bedd-10bcb36a5a2b"
   },
   "source": [
    "Translate English text to over 400 languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4687ec-c508-4a07-bd02-14f7c7d7d626",
   "metadata": {
    "id": "ff4687ec-c508-4a07-bd02-14f7c7d7d626"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip3 -q install torch transformers accelerate sentencepiece tokenizers optimum gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2a116-525a-4d8c-a1c0-2f0a86fd3554",
   "metadata": {
    "id": "69f2a116-525a-4d8c-a1c0-2f0a86fd3554"
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "# import spaces\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c06ec-3ec2-4b14-9262-2d22cc6daa54",
   "metadata": {
    "id": "653c06ec-3ec2-4b14-9262-2d22cc6daa54"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e1467-285b-4898-86ec-1ab93af60e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cc8eb-fce2-449f-a57b-858a5af6c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of language codes\n",
    "tokenizer_3b_mt = AutoTokenizer.from_pretrained(\"google/madlad400-3b-mt\", use_fast=True)\n",
    "language_codes = [token for token in tokenizer_3b_mt.get_vocab().keys() if token.startswith(\"<2\")]\n",
    "remove_codes = ['<2>', '<2en_xx_simple>', '<2translate>', '<2back_translated>', '<2zxx_xx_dtynoise>', '<2transliterate>']\n",
    "language_codes = [token for token in language_codes if token not in remove_codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef935522-ef57-49c7-a85b-38bd76c1e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of translation models\n",
    "model_choices = [\n",
    "    \"google/madlad400-3b-mt\", \n",
    "    \"google/madlad400-7b-mt\", \n",
    "    \"google/madlad400-10b-mt\", \n",
    "    \"google/madlad400-7b-mt-bt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a9d87-d4c3-4f72-bbe9-2db70491694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to store loaded tokenizers and models\n",
    "model_resources = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbe3c8-51b4-44d0-91c7-9f15f26dda82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_model(model_name):\n",
    "    \"\"\"\n",
    "    Load tokenizer and model for a chosen model name.\n",
    "    \"\"\"\n",
    "    if model_name not in model_resources:\n",
    "        # Load tokenizer and model for first time\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "        model.to_bettertransformer()\n",
    "        model.to(device)\n",
    "        model_resources[model_name] = (tokenizer, model)\n",
    "    return model_resources[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200f589-7fb5-409c-b513-63eaaaa83331",
   "metadata": {
    "id": "0200f589-7fb5-409c-b513-63eaaaa83331"
   },
   "outputs": [],
   "source": [
    "# @spaces.GPU\n",
    "def translate(text, target_language, model_name):\n",
    "    \"\"\"\n",
    "    Translate the input text from English to another language.\n",
    "    \"\"\"\n",
    "    # Load tokenizer and model if not already loaded\n",
    "    tokenizer, model = load_tokenizer_model(model_name)\n",
    "    \n",
    "    text = target_language + text\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=128000)\n",
    "    text_translated = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return text_translated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b0d8a-3824-4320-8511-34a185588948",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"MADLAD-400 Translation\"\n",
    "description = \"\"\"\n",
    "Translation from English to over 400 languages based on [research](https://arxiv.org/pdf/2309.04662) by Google DeepMind and Google Research. Initial inference will be slow as models load.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990628a9-c5c7-4f58-b968-6c6a355a5a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = gr.Textbox(\n",
    "    label=\"Text\",\n",
    "    placeholder=\"Enter text here\"\n",
    ")\n",
    "target_language = gr.Dropdown(\n",
    "    choices=language_codes,\n",
    "    value=\"<2haw>\",\n",
    "    label=\"Target language\"\n",
    ")\n",
    "model_choice = gr.Dropdown(\n",
    "    choices=model_choices, \n",
    "    value=\"google/madlad400-3b-mt\", \n",
    "    label=\"Model\"\n",
    ")\n",
    "output_text = gr.Textbox(label=\"Translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863999e-23a7-4e42-8219-c139aadd89ab",
   "metadata": {
    "id": "a863999e-23a7-4e42-8219-c139aadd89ab"
   },
   "outputs": [],
   "source": [
    "# Define Gradio application\n",
    "demo = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[input_text, target_language, model_choice],\n",
    "    outputs=output_text,\n",
    "    title=title,\n",
    "    description=description\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d810ea1-74ea-440f-aa64-e15f4630b0da",
   "metadata": {
    "id": "1d810ea1-74ea-440f-aa64-e15f4630b0da"
   },
   "outputs": [],
   "source": [
    "# Set queue with default settings\n",
    "demo.queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef17835-cda7-4879-a3f7-be2c776dae51",
   "metadata": {
    "id": "8ef17835-cda7-4879-a3f7-be2c776dae51"
   },
   "outputs": [],
   "source": [
    "# Launch Gradio application\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413fac8-1703-451b-b22d-d659bcd88dc4",
   "metadata": {
    "id": "a413fac8-1703-451b-b22d-d659bcd88dc4"
   },
   "outputs": [],
   "source": [
    "# Close Gradio application\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda6a60-9492-40fe-a30f-286bb8b4c11b",
   "metadata": {
    "id": "efda6a60-9492-40fe-a30f-286bb8b4c11b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
